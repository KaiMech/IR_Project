{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eca74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shelve\n",
    "import pickle\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "01d177e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import orjson as _json\n",
    "    loads = _json.loads\n",
    "except Exception:\n",
    "    import json as _json\n",
    "    loads = _json.loads\n",
    "\n",
    "corpus = '../Inverted_index/trec-tot-2025-corpus.jsonl.gz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42dc4a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "def AND(l1, l2):\n",
    "    # note: this method assumes that both lists are sorted and do not contain any duplicates (which if the input comes from a posting list is given)\n",
    "    p1 = 0\n",
    "    p2 = 0\n",
    "    sqrtJump1 = max(math.isqrt(len(l1)), 1)\n",
    "    sqrtJump2 = max(math.isqrt(len(l2)), 1)\n",
    "    result = []\n",
    "    while p1 < len(l1)  and p2 < len(l2):\n",
    "        if l1[p1] == l2[p2]:\n",
    "            result.append(l1[p1])\n",
    "            p1 += 1\n",
    "            p2 += 1\n",
    "        # skip pointer in first list\n",
    "        elif p1 % sqrtJump1 == 0 and p1 + sqrtJump1 < len(l1) and l1[p1 + sqrtJump1] <= l2[p2]:\n",
    "            p1 += sqrtJump1\n",
    "        # skip pointer in second list\n",
    "        elif p2 % sqrtJump2 == 0 and p2 + sqrtJump2 < len(l2) and l2[p2 + sqrtJump2] <= l1[p1]:\n",
    "            p2 += sqrtJump2\n",
    "        elif l1[p1] < l2[p2]:\n",
    "            p1 += 1\n",
    "        else:\n",
    "            p2 += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8241d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OR(l1, l2):\n",
    "    # note: this method assumes that both lists are sorted and do not contain any duplicates (which if the input comes from a posting list is given)\n",
    "    p1 = 0\n",
    "    p2 = 0\n",
    "    result = []\n",
    "    while p1 < len(l1) and p2 < len(l2):\n",
    "        if l1[p1] < l2[p2]:\n",
    "            result.append(l1[p1])\n",
    "            p1 += 1\n",
    "        elif l1[p1] > l2[p2]:\n",
    "            result.append(l2[p2])\n",
    "            p2 += 1\n",
    "        else: \n",
    "            result.append(l1[p1])\n",
    "            p1 += 1\n",
    "            p2 += 1\n",
    "    while p1 < len(l1):\n",
    "        result.append(l1[p1])\n",
    "        p1 += 1\n",
    "    while p2 < len(l2):\n",
    "        result.append(l2[p2])\n",
    "        p2 += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65414a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for stopword removal\n",
    "stop = set(stopwords.words('english') + list(string.punctuation))\n",
    "\n",
    "\n",
    "# Function to tokenize and preprocess a document\n",
    "def preprocess(text):\n",
    "    tokens = set(word_tokenize(text.lower())) # get all tokens\n",
    "    return [i for i in tokens if i not in stop] # get all tokens without stopwords\n",
    "\n",
    "    # add lematization later\n",
    "    \n",
    "def query_inverted_index(query):\n",
    "    with shelve.open(\"../Inverted_index/inverted_index.db\") as db:\n",
    "        terms = [t for t in preprocess(query) if t in db]\n",
    "        if not terms:\n",
    "            return []\n",
    "        terms.sort(key=lambda t: len(db[t]))\n",
    "\n",
    "        result = db[terms[0]]\n",
    "        for term in terms[1:]:\n",
    "            result = AND(result, db[term])   \n",
    "        return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a953feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "[np.int32(78), np.int32(7853), np.int32(72787), np.int32(97220), np.int32(99978), np.int32(111464), np.int32(196139), np.int32(246186), np.int32(403184), np.int32(448119), np.int32(522096), np.int32(673521), np.int32(777589), np.int32(777915), np.int32(916041), np.int32(916189), np.int32(1025520), np.int32(1093229), np.int32(1106968), np.int32(1106992), np.int32(1124224), np.int32(1158512), np.int32(1338601), np.int32(1351599), np.int32(1418426), np.int32(1647447), np.int32(1973823), np.int32(1981656), np.int32(2029003), np.int32(2097964), np.int32(2176637), np.int32(2180791), np.int32(2182218), np.int32(2248520), np.int32(2251305), np.int32(2380829), np.int32(2540332), np.int32(2542449), np.int32(2543726), np.int32(2544878), np.int32(2549309), np.int32(2552773), np.int32(2561199), np.int32(2561598), np.int32(2563846), np.int32(2564319), np.int32(2598515), np.int32(2600323), np.int32(2601041), np.int32(2602615), np.int32(2768719), np.int32(2794708), np.int32(2804553), np.int32(3279004), np.int32(3387632), np.int32(3481089), np.int32(3532473), np.int32(3539356), np.int32(3553003), np.int32(3611241), np.int32(3632045), np.int32(3637096), np.int32(3666235), np.int32(3788378), np.int32(4042943), np.int32(4110293), np.int32(4345457), np.int32(4360440), np.int32(4661999), np.int32(5193219), np.int32(5360267), np.int32(5395422), np.int32(5413022), np.int32(5545655), np.int32(5706755), np.int32(5710536), np.int32(5712279), np.int32(5717584), np.int32(5724558), np.int32(5764818), np.int32(5779720), np.int32(5785743), np.int32(5796392), np.int32(5801484), np.int32(5810068), np.int32(5834095), np.int32(5835033), np.int32(5847525), np.int32(5849378), np.int32(5851235), np.int32(5889899), np.int32(5907555), np.int32(5934621), np.int32(5939777), np.int32(5998316), np.int32(6008310), np.int32(6026330), np.int32(6074390), np.int32(6079610), np.int32(6108812), np.int32(6180025), np.int32(6278148), np.int32(6323377), np.int32(6369827), np.int32(6402587)]\n"
     ]
    }
   ],
   "source": [
    "query = \"sciences are great because people Mannheim\"\n",
    "\n",
    "result = query_inverted_index(query)\n",
    "print(len(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e28c614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   query_id                                              query\n",
      "0      3000  I remember this certain type of cheese from wa...\n",
      "1      3001  I saw only this scene, on YouTube or Vimeo a l...\n",
      "2      3002  young boy works with older master to learn jud...\n",
      "3      3003  This building looks like a big hotel in New Yo...\n",
      "4      3004  I vividly remember strolling through the archi...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(testdata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0923e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['39', '305', '324']\n"
     ]
    }
   ],
   "source": [
    "import indexed_gzip\n",
    "\n",
    "def read_lines_from_gzip(gz_path, line_numbers):\n",
    "    line_numbers_set = set(line_numbers)  # faster lookup\n",
    "    lines = []\n",
    "    \n",
    "    with indexed_gzip.open(filename=gz_path, mode='rb') as f:\n",
    "        for i, line in enumerate(f, start=1):\n",
    "            data = loads(line)\n",
    "            id = data.get(\"id\", \"\")\n",
    "            if i in line_numbers_set:\n",
    "                lines.append(id)\n",
    "            if len(lines) == len(line_numbers_set):\n",
    "                break\n",
    "    return lines\n",
    "\n",
    "# Example usage\n",
    "line_numbers_to_read = [2, 5, 10]\n",
    "lines = read_lines_from_gzip(corpus, line_numbers_to_read)\n",
    "\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7bf5aec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 Q0 12 1 0.25 1\n",
      "3000 Q0 39 2 0.25 1\n",
      "3000 Q0 290 3 0.25 1\n",
      "3000 Q0 303 4 0.25 1\n"
     ]
    }
   ],
   "source": [
    "def evaluateOnJSON(filenames, runID):\n",
    "    for filename in filenames:\n",
    "        testdata = pd.read_json(filename, lines = True)\n",
    "        testdata[\"result\"] = [[1, 2, 3, 4] for _ in range(len(testdata))]\n",
    "        for index, row in testdata.iterrows():\n",
    "            result = query_inverted_index(row[\"query\"])\n",
    "            result = [1, 2, 3, 4] # remove             \n",
    "            pageIDS = read_lines_from_gzip(corpus, result) \n",
    "            for i in range(len([1, 2, 3, 4])):\n",
    "                print(f\"{row[\"query_id\"]} Q0 {pageIDS[i]} {i + 1} {1.0 / len(result)} {runID}\")\n",
    "            break\n",
    "        \n",
    "\n",
    "# runID ggfs. manuell setzen :)\n",
    "evaluateOnJSON([\"../data/tot25/test-2025-queries.jsonl\"], \"1\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
